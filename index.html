<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title> Capturing Motion </title>

    <link rel="icon" href="./static/images/lvbench.jpg">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="./static/css/leaderboard.css">
    <link rel="stylesheet" href="./static/css/video-player.css">


    <script type="text/javascript" src="static/js/sort-table.js" defer></script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/explorer-index.js"></script>
    <script src="./static/js/question_card.js"></script>

    <style>
        .no-sort {
            cursor: default;
            pointer-events: none;
            background-image: none !important; /* Remove the sort arrow */
        }
    </style>
</head>
<body>



<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title is-bold">
                        <img src="static/images/lvbench.jpg" style="width:1.6em;vertical-align: middle" alt="Logo"/>
                        <span class="video-mme" style="vertical-align: middle">Motion-caption</span>
                    </h1>
                    <h2 class="subtitle is-3 publication-subtitle" , style="margin-bottom: 20px;">
                        Datasets with more detailed action descriptions
                    </h2>


                    <div class="is-size-5 publication-authors">

                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                <a href="https://arxiv.org/abs/2406.08035"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            <!-- Code Link. -->
                            <span class="link-block">
                <a href="https://github.com/motion-caption/motion-caption.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
                            <!-- Dataset Link. -->
                            <span class="link-block">
                <a href="https://huggingface.co/datasets/THUDM/LVBench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ðŸ“Š</p>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>

                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container" style="margin-bottom: 2vh;">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Introduction</h2>
                <div class="content has-text-justified">
                    With the widespread application of video understanding tasks, generating accurate and comprehensive 
                    video captions has become a key objective for large-scale video understanding models. However, existing
                    models often fail to sufficiently capture dynamic video information, resulting in captions lacking 
                    detailed descriptions of actions and motion changes. This limitation hinders the performance of models 
                    in real-world scenarios such as automatic video summarization and video surveillance. This paper 
                    proposes a novel data processing and model fine-tuning approach to address this issue. We first 
                    preprocess existing datasets to ensure that the captions contain visual information and include more 
                    detailed action descriptions. Additionally, we integrate multi-source data, combining human-labeled 
                    action data with virtual action data generated using Unity3D. Through effective data fusion and a 
                    staged training strategy, we fine-tune existing large-scale video understanding models to generate 
                    captions with richer dynamic information. Experimental results demonstrate significant performance 
                    improvements across multiple datasets, especially in capturing and generating action-related 
                    descriptions, with notable advancements compared to the original models. The proposed method offers a 
                    new approach for capturing dynamic information in video understanding models and provides a more 
                    practical solution for real-world applications.
                </div>
            </div>
        </div>
        <!--/ Abstract. -->
    </div>
</section>


<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
        <h1 class="title is-1 mathvista_other">
            <span class="mathvista_other" style="vertical-align: middle">Datasets</span>
        </h1>
    </div>
</section>

<!--Example-->
<section class="section">
    <div class="container">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths" style="width: 100%;">

                <h2 class="title is-3">Here are examples of tht four sub-datasets. </h2>
                <div class="content has-text-justified">

                    <div>
                        <div class="content has-text-centered">
                            <img src="static/images/4_dataset.jpeg" style="width: 80%;"/>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    </div>
    </div>
</section>



<!--Statistics-->
<section>
    <div class="columns is-centered">
        <div class="column">
            <div class="content has-text-centered">
                <h2 class="title is-3" style="margin-top: 30px;">Statistics</h2>

                <div class="container-wrapper" style="display: flex; justify-content: center; align-items: center;">
                    <div id="container"></div>
                    <div id="image-container" style="margin-right: 1px;">
                        <img src="static/images/distribution.png" alt="data-composition"
                             style="max-width: 100%; display: inline-block;"/>
                    </div>
                </div>
<!--                 <p style="text-align: center; margin-left: auto; margin-right: auto; width: 50%;">
                    (Left) <strong>Video categories.</strong> Our dataset contains 6 major categories and 21
                    subcategories. <br> (Right) Performance radar chart of different models on LVBench.<br/>
                </p> -->
            </div>
        </div>
    </div>
</section>

<!--number-->
<section>
    <div class="columns is-centered">
        <div class="column">
            <div class="content has-text-centered">
                <h2 class="title is-3">Exact Quantity</h2>
                <img src="static/images/number.png" alt="data-composition" style="max-width: 50%;"/>
                
            </div>
        </div>
    </div>
</section>

<!--Experiments-->
<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
        <h1 class="title is-1 mathvista_other">Experimental Results</h1>
    </div>
</section>

<!--result-->
<section class="section">
    <div class="container">
        <div class="columns is-centered m-6">
            <div class="column is-full has-text-centered content">
                <h2 class="title is-3">Caption Comparison</h2>
                <div class="box m-5">
                    <div class="content has-text-centered">
                        <img src="static/images/image.png" alt="grade-lv" width="80%"/>
                        <p>As shown in figure, the comparison reveals that the fine-tuned model is capable of 
                            generating more detailed and comprehensive descriptions of object movements and interactions.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


</section>
<section class="hero is-light is-small">
    <div class="hero-body has-text-centered">
        <h1 class="title is-1 mathvista_other" id="citation">Citation</h1>
    </div>
</section>

<!--citation-->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
    <pre><code>@misc{wang2024lvbench,
      title={Capturing Motion: Fine-Tuning Video Captioning Models with Dynamic Action Data},
      author={Zhiqin Fang and Lefan Wang and Zhuoyi Yang and Jiayan Teng and Yean Cheng and Shiyu Huang and Yuxiao Dong and Zhaofeng He and Jie Tang},
      year={2024},
      eprint={2406.08035},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre>
    </div>
</section>

<footer class="footer">
    <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
        <div class="column is-8">
            <div class="content">
                <p style="text-align: center;">
                    This website is adapted from <a href="https://video-mme.github.io">Video-MME</a>, licensed under a
                    <a rel="license"
                       href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
            </div>
        </div>
    </div>
    <!-- </div> -->
</footer>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        updateRowNumbers();
        document.querySelector("#results").addEventListener("click", updateRowNumbers);
    });

    function updateRowNumbers() {
        const rows = document.querySelectorAll("#results tbody tr");
        rows.forEach((row, index) => {
            row.querySelector("td").innerText = index + 1;
        });
    }
</script>

</body>
</html>

